\documentclass[10pt]{article}

%%% PACKAGES

\usepackage{xr}
\externaldocument{RNARedPrint}


\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
% \usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
%   \let\itemize\compactitem
%   \let\enditemize\endcompactitem
%   \let\enumerate\compactenum
%   \let\endenumerate\endcompactenum
%   \let\description\compactdesc
%   \let\enddescription\endcompactdesc
%   \pltopsep=1pt
%   \plitemsep=1pt
%   \plparsep=1pt
\usepackage{hyperref}
\usepackage{xspace}

\usepackage[margin=1in]{geometry}

\usepackage{amsmath,amssymb}
\usepackage{bm}
\usepackage{verbatim}
\usepackage{longtable}
\usepackage[vlined]{algorithm2e}

\usepackage{xifthen}
\usepackage{stmaryrd}

\usepackage{xcolor}

\usepackage{todonotes}


\hypersetup{
    bookmarks=false,         % show bookmarks bar?
    unicode=false,          % non-Latin characters in Acrobat’s bookmarks
    pdftoolbar=true,        % show Acrobat’s toolbar?
    pdfmenubar=true,        % show Acrobat’s menu?
    pdffitwindow=true,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=red!70!black,          % color of internal links (change box color with linkbordercolor)
    citecolor=blue!50!black,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=green!50!black           % color of external links
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Rolf's includegraphicstop
\makeatletter
\newsavebox{\@alignepsbox}
\newlength{\@aligneps}
\newcommand{\includegraphicstop}[2][]{%
\sbox{\@alignepsbox}{\includegraphics[#1]{#2}}%
\setlength{\@aligneps}{-\ht\@alignepsbox}%
\addtolength{\@aligneps}{2ex}%
\raisebox{\@aligneps}{\usebox{\@alignepsbox}}}
\makeatother


%\makeatletter
%\let\oldlt\longtable
%\let\endoldlt\endlongtable
%\def\longtable{\@ifnextchar[\longtable@i \longtable@ii}
%\def\longtable@i[#1]{\begin{figure}[t]
%\onecolumn
%\begin{minipage}{0.5\textwidth}
%\oldlt[#1]
%}
%\def\longtable@ii{\begin{figure}[t]
%\onecolumn
%\begin{minipage}{0.5\textwidth}
%\oldlt
%}
%\def\endlongtable{\endoldlt
%\end{minipage}
%\twocolumn
%\end{figure}}
%\makeatother

%%%%%%%%%%%%%%%%% Theorems %%%%%%%%%%%%%%%%%%%%%%%%%

 \newtheorem{theorem}{Theorem}
 \newtheorem{definition}[theorem]{Definition}
 \newtheorem{remark}[theorem]{Remark}
 \newtheorem{corollary}[theorem]{Corollary}
 \newtheorem{lemma}[theorem]{Lemma}
 \newtheorem{proposition}[theorem]{Proposition}

\newtheorem{observation}[theorem]{Observation}

%\newtheorem{algorithm}{Algorithm}
\newtheorem{axiom}{Axiom}
\newtheorem{hypothesis}{Working Hypothesis}
\newenvironment{proof}[1][]{\noindent \emph{Proof}\ifthenelse{\equal{#1}{}}{}{ (#1)}.~}{\hfill$\Box$}


%%% macros for notation in DP framework
\newcommand{\val}{\bar S} % valuation aka assignment
\newcommand{\dep}{\operatorname{dep}}
\newcommand{\energy}[1]{\operatorname{e}_{#1}}
\newcommand{\numberof}{\operatorname{\#}}
\newcommand{\partfun}[1]{\mathcal{Z}_{#1}}
\newcommand{\separator}[2]{\operatorname{sep}(#1,#2)}
\newcommand{\difference}[2]{\operatorname{diff}(#1 \rightarrow #2)}
\newcommand{\real}{\mathbb{R}}
\newcommand{\genmarg}[1]{(\!|\!#1\!|\!)}
\newcommand{\gencomb}[1]{\langle\!|#1|\!\rangle}
\newcommand{\Message}[2]{m_{#1\rightarrow #2}}


\newcommand{\energyModel}{{\cal M}}
\newcommand{\structureElements}{{\cal SE}}
\newcommand{\powerSet}[1]{2^{#1}}
\newcommand{\underConstruction}[1]{{\LARGE$\triangle$\Large\!\!\!\!!}$\quad$\textcolor{red}{#1}}
\newcommand{\argmin}{\operatorname*{arg\,min}}
\newcommand{\objective}{{\mathbb{F}}}

\newcommand{\partseqs}{\mathcal{P\!S}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\R}{\mathcal{R}}
\renewcommand{\S}{\mathcal{S}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}

\newcommand{\width}{w}

\newcommand{\sample}{\texttt{Sample}}
\newcommand{\elim}[2]{\operatorname{elim}(#1,#2)}
\newcommand{\edgesToR}{E^r_T}

\newcommand{\phitotal}{\phi_{\operatorname{m}}}

\newcommand{\Ebp}[2]{E^{\textrm{bp}}_{#1}(#2)}
\newcommand{\Ehp}[1]{E^{\textrm{hp}}(#1)}
\newcommand{\Eint}[1]{E^{\textrm{int}}(#1)}

\newcommand{\Def}[1]{\emph{#1}}

\newcommand{\TargetE}{E^{\star}}

\newcommand{\TODO}[1]{\textcolor{red!70!black}{\textbf{TODO: #1}}}

\newcommand{\parHead}[1]{\Final{\paragraph{#1}}}

\newcommand{\Final}[1]{#1}
%% Uncomment the line below for ``Final'' version
\renewcommand{\Final}[1]{}

\newcommand{\Design}[1]{{\sf Designs}^{\star}(#1)}
\newcommand{\NumDesign}{\ensuremath{\#}{\sf Designs}\xspace}
\newcommand{\IS}[1]{{\sf IndSets}(#1)}
\newcommand{\Nuc}[1]{{\sf #1}}
\newcommand{\Ab}{\Nuc{A}}
\newcommand{\Cb}{\Nuc{C}}
\newcommand{\Gb}{\Nuc{G}}
\newcommand{\Ub}{\Nuc{U}}

\newcommand{\GCb}{\Gb\Cb}

\newcommand{\Software}[1]{{\ttfamily #1}}

\newcommand{\RNAblueprint}{{\tt \bfseries{}\color{black!85} RNA\textcolor{blue!70!black}{Blue}Print}}
\newcommand{\ourprog}{{\tt \bfseries{}\color{black!85}RNA\textcolor{red!70!black}{Red}Print}}


\newcommand{\evalfor}[2]{#1(#2)}
\newcommand{\substitute}[2]{#1\cup#2}

\renewcommand{\gets}{:=}

\setlength{\parskip}{.2em}


\newcommand{\citep}[1]{\cite{#1}}
\newcommand{\citet}[1]{\cite{#1}}

%% highlight changes for revision in red
\newcommand{\revised}[1]{{\color{red} #1}}
\newenvironment{revision}{\color{red}}{\color{black}}

%%% end macro defs



\begin{document}
\onecolumn

\appendix
{\centering \Large \textbf{Supplementary Material}\\[1em] Fixed-Parameter Tractable Sampling\\ for RNA Design with Multiple Target Structures\\%
}

\medskip
\begin{center}
\large Stefan Hammer, Wei Wang, Sebastian Will and Yann Ponty
\end{center}

\begin{revision}
  \section{Run times for generating samples}

To illustrate the efficiency and practical feasibility of our Boltzmann sampling approach, we show the distributions of run times (Intel(R) Core(TM) i7-4770 CPU) for generating 20.000 samples (over the Modena benchmark instances and grouped by benchmark sub-set). Since producing a controlled Boltzmann sampling requires significant pre-computation, it is informative to separately show construction and sampling times (Figure~\ref{fig:run-times-redprint}).

A fair comparison to sampling times by other tools can hardly be given, since the other tools produce samplings of very different nature. In particular, Modena does not make any guarantees on properties of the sampling. Non-surprisingly, this allows it to sample significantly faster (several orders of magnitudes).

The comparison to run times of \RNAblueprint{} is still interesting, since this tool generates---similarly to our tool---\emph{controlled} samples. Nevertheless, as we argue the Boltzmann sampling is fundamentally more flexible than uniform sampling as generated by \RNAblueprint. Moreover, in this concrete case, \ourprog{} samples based on the rather complex stacking energy model, which introduces much stronger dependencies than required for uniform sampling. Technically, these stronger dependencies increase the tree width; here, the increase is exactly the same as the one from the base pair to the stacking model as reported in Figure~\ref{}. In this light, \ourprog{} performs even particularly well, beating \RNAblueprint{} most of the time with only a few exceptions for particularly hard instances. The results for \RNAblueprint{} are shown in Figure~\ref{fig:run-times-rbp}. 

\begin{figure}[tbh]
  \centering
  \includegraphics[width=0.45\textwidth]{Figs/RunTimes/construction_time_sets}\quad%
  \includegraphics[width=0.45\textwidth]{Figs/RunTimes/sample_time_sets}\\
  \includegraphics[width=0.45\textwidth]{Figs/RunTimes/construction_time_sets_bp}\quad%
  \includegraphics[width=0.45\textwidth]{Figs/RunTimes/sample_time_sets_bp}
  \caption{\todo[inline]{caption Stefan?}}
  \label{fig:run-times-redprint}
\end{figure}
\begin{figure}[tbh]
  \centering
  \includegraphics[width=0.45\textwidth]{Figs/RunTimes/construction_time_sets_rbp}\quad%
  \includegraphics[width=0.45\textwidth]{Figs/RunTimes/sample_time_sets_rbp}
  \caption{\todo[inline]{caption Stefan?}}
  \label{fig:run-times-rbp}
\end{figure}

\end{revision}

\section{Illustrating multi-dimensional Boltzmann sampling for three pseudoknot-free target structures}

    In analogy to Fig.~\ref{fig:energydist-pk} of the main text,
    Fig.~\ref{fig:energydist} illustrates our multi-dimensional sampling
    strategy for three pseudoknot-free target structures (example instance
    from the \texttt{Modena} benchmark). The figure shows Turner energy
    distributions of single structures from sampling with different weight
    parameters, where weights are trained to target specific energies. For
    comparison, the figure shows distributions from uniform and Boltzmann
    sampling at respective homogenous weights $1$ and $e^\beta$.

    Fig.~\ref{fig:gc-content} shows the distributions of the GC content of the samples, while targeting different combinations of energies in this experiment. For completeness, we also report corresponding results for the analogous experiment from the main text. We observe that in addition to the target energies, also the feature $\GCb\%$ is narrowly defined by the multi-dimensional Boltzmann sampling strategy. In comparison, for uniform sampling and Boltzmann sampling at high weight $e^\beta$, where the \GCb\% is not controlled, we obtain much broader distributions. 

\begin{figure}[tb]
      \begin{center}
        %{\sf \bfseries A}\includegraphicstop[width=0.32\textwidth]{Figs/offset2}\hspace{.5cm}
        %{\sf \bfseries B}
        \includegraphicstop[width=0.8\textwidth]{Figs/energy_distribution}
      \end{center}
      \caption{%
        Targeting specific energies using multi-dimensional Boltzmann
        sampling. We show the Turner energy distributions for
        three target structures R1, R2 and R3. By
        targeting the respective free energies $(-40,-40,-20)$ and
        $(-20,-20,-20)$ for the target structures (annotated in red and
        blue, resepectively), we demonstrate the
        effectivity of our adaptive multi-dimensional Boltzmann sampling
        procedure; moreover, for comparison, the distributions for uniform
        (U) and Boltzmann (B) samples---respectively associated with
        homogenous weights $1$ and $e^\beta$.
%    ($\delta=0.05, \delta'=0.1, \gamma=1.1, \psi=20, n=1000$)
  }
  \label{fig:energydist}
\end{figure}

\begin{figure}
  \begin{center}
    {\sf \bfseries A}~\includegraphicstop[width=0.45\textwidth]{Figs/Plots/PKB00211_PKB00239_0_GC_content}
    ~~~~~{\sf \bfseries B}~\includegraphicstop[width=0.45\textwidth]{Figs/Plots/supp_3str_GC_content}
  \end{center}
  \caption{Distribution of the \GCb-content \GCb\% in the experiments of (A) Fig.~\ref{fig:energydist-pk} of the main text and (B) Suppl.~Fig.~\ref{fig:energydist}.}
  \label{fig:gc-content}
\end{figure}

\section{Immediate benefits of positive design for negative design}

Already previous work on RNA Design, e.g. INFO-RNA and Incarnation, observed
that---put briefly---negative design benefits from positive design. Here, more
concretely, we simply \emph{demonstrate} this effect (for small examples), where
we consider \Def{negative design} as  
designing RNA sequences that fold with high probability $Pr(R|S)$ into the
given target structure $R$; and \Def{positive design}, as generating one or
many sequences that have a low energy for $R$.

For each of two small examples, a single-stem and a double-stem structure, we produce a uniform and a weighted Boltzmann
sampling, each of 10000 sequenes. For each sampled sequence $S$, we determine
the Turner energy $E(S,R)$ as well as the
%difference $E_\Delta(S,R)$ of $E(S,R)$ to the ensemble energy $E_{\text{ens}}(S)$ of $S$ 
probability $Pr(R|S)$ of the structure $R$ in the ensemble of sequence $S$ 
(where the energies are calculated in the Turner model using RNAfold). 

Note that low energy $E(S|R)$ is (non-linearly) correlated with high
probability $Pr(S|R)$, the probability to see $S$ in the Boltzmann distribution
of sequences folding into $R$. Recall that the probability $Pr(R|S)$ can be
calculated as $\exp(-E(S,R)/RT)/Z(S)$,
where $Z(S)=\sum_{R'} \exp(-E(S,R')/RT)$.
%
Consequently, Figure~\ref{fig:negforpos} ultimately illustrates the dependencies
between $Pr(S|R)$ and $Pr(R|S)$ for uniform samples and low energy samples
(where those samples can be efficiently generated due to our Boltzmann sampling
strategy). For our examples, we observe (Fig.~\ref{fig:negforpos}) that Boltzmann sampling with weight 500 (green), generates good negative designs 
with substantially higher probability than uniform sampling (blue).

% and high energy difference $E_\Delta(S,R)=E_{\text{ens}}(S)-E(S,R)$, with high probability $\Pr(R|S)$.
% 
% To see the latter, recall that the \Def{ensemble energy $E_{\text{Ens}}(S)$} is defined as
% $$
% E_{\text{ens}}(S) = -RT \ln( Z(S) ),
% $$ 
% based on the partition function $Z(S)=\sum_{R'} \exp(-E(S,R')/RT)$
% such that 
% $$
% E(S,R) - E_{\text{ens}}(S) 
% =
% -RT \ln Pr(R|S),
% $$  
% which can be derived by term transformation 
% \begin{align*}
% -RT \ln P(R|S) &= -RT \ln [ exp(-E(S,R)/RT) / Z(S) ] \\&= -RT \ln (exp(-E(S,R)/RT)) - (-RT\ln Z(S))
% \\&=  E(S,R) - E_{\text{Ens}}(S). 
% \end{align*}

\begin{figure}
\textbf{A}~\includegraphicstop[width=0.48\textwidth]{Figs/Plots/stem_weight1-500_mean}%
\textbf{B}~\includegraphicstop[width=0.48\textwidth]{Figs/Plots/doublestem_weight1-500_mean}%
\caption{Comparison of uniform sampling and Boltzmann sampling with
weight $\pi=500$. We show results for two different small structures: (A) single stem structure (B) double stem structure. For each respective structure $R$, we plot the energies $E(S,R)$ of
10000 sampled sequences against the probabilities $Pr(R|S)$ (in log scale). For illustrating the trend, we show moving averages over windows of $\pm 1$ kcal. Note that while only the energy $E(S,R)$ is directly controlled by Boltzmann sampling, this strongly impacts the common negative design objective $Pr(R|S)$.}
\label{fig:negforpos}
\end{figure}

\section{Parameters for the base pair and the stacking energy model}
\label{appsec:modelparameters}

We trained parameters for two RNA energy models to approximate the
Turner energy model, as implemented in the \Software{ViennaRNA}
package.  In the \Def{base pair model}, the total energy of a sequence $S$
for an RNA structure $R$ is given as sum of base pair energies, where
we consider six types of base pairs distinguishing by the bases $\Ab$-$\Ub$,
$\Cb$-$\Gb$ or $\Gb$-$\Ub$ (symmetrically) and between stacked and non-stacked base
pairs; here, we consider base pairs $(i,j)\in R$ \Def{stacked} iff
$(i+1,j-1)\in R$, otherwise \Def{non-stacked}. In the \Def{stacking model},
our features are defined by the stacks, i.e. pairs $(i,j)$ and
$(i+1,j-1)$ which both occur in $R$; we distinguish 18 types based on
$S_i,S_j,S_{i+1},S_{j-1}$ (i.e. all combinations that allow canonical
base pairs; the configurations $S_i,S_j,S_{i+1},S_{j-1}$ and
$S_{i+1},S_{j-1},S_j,S_i$ are symmetric).

Both models describe the energy assigned to a pair of sequence and
structure in linear dependency of the number of features and their
weights. We can thus train weights for linear predictors of the Turner
energy in both models.

For this purpose, we generated 5000 uniform random RNA sequences of
random lengths between 100 and 200. For each sample, we predict the
minimum free energy and corresponding structure using the ViennaRNA
package; then, we count the distinguished features (i.e., base pair or
stack types). The parameters are estimated fitting linear models
without intercept (\texttt{R} function \texttt{lm}). For both models,
\texttt{R} reports an adjusted R-squared value of 0.99. The resulting
parameters are reported in Tables~\ref{tab:basepairmodel} and
\ref{tab:stackingmodel}.

For validating the trained parameters, we generate a second
independent test set of random RNA sequences in the same
way. Fig.~\ref{fig:training-cor} shows correlation plots for the
trained parameters in the base pair and stacking models for predicting
the Turner energies in the test set with respective correlations of
$0.95$ an $0.94$.

\begin{figure}
  \centering
  A)\includegraphicstop[width=0.4\textwidth,trim=0 0 0 50,clip]{Figs/basepaircor}
  B)\includegraphicstop[width=0.4\textwidth,trim=0 0 0 50,clip]{Figs/stackingcor}
  \caption{Validation of the trained parameters for the A) base pair
    model B) stacking model for predicting energies of the
    independently sampled sequences in the test set. We show
    correlation plots against the Turner energies reported by the
    ViennaRNA package.}
  \label{fig:training-cor}
\end{figure}

\begin{table}[b]
  \centering
  \caption{Trained weights for the base pair energy model.}
  \label{tab:basepairmodel}
  \begin{tabular}{c@{\quad}c@{\quad}c@{\quad}|@{\quad}c@{\quad}c@{\quad}c}
    \multicolumn{3}{c}{non-stacked} & \multicolumn{3}{c}{stacked}\\
    AU      & CG       & GU      & AU       & GC       & GU \\\hline
    1.26630 & -0.09070 & 0.78566 & -0.52309 & -2.10208 & -0.88474
  \end{tabular}
\end{table}

% GC_IN = -0.09070;
% AU_IN = 1.26630;
% GU_IN = 0.78566;
% GC_TERM = -2.10208;
% AU_TERM = -0.52309;
% GU_TERM = -0.88474;

\begin{table}[b]
  \centering
  \caption{Trained weights for the stacking energy model (the rows specify $S_i,S_j$; the columns, $S_{i+1},S_{j-1}$; we do not show the symmetric weights).}
  \label{tab:stackingmodel}
  \begin{tabular}{c@{\quad}|@{\quad}c@{\quad}c@{\quad}c@{\quad}c@{\quad}c@{\quad}c@{\quad}c@{\quad}c}
       & AU & CG & GC & GU & UA & UG \\\hline
    AU &
-0.18826 &
-1.13291 &
-1.09787 &
-0.38606 &
-0.26510 &
-0.62086
    \\
    CG &
-1.11752 &
-2.23740 &
-1.89434 &
-1.22942 &
-1.10548 &
-1.44085
    \\
    GU &
-0.55066 &
-1.26209 &
-1.58478 &
-0.72185 &
-0.49625 &
-0.68876
    \\
  \end{tabular}
\end{table}

\section{Contribution of terms to the MultiDefect score}

\newcommand{\EnsE}{\text{\rm G}} %ensemble energy


Figure~\ref{fig:contribtions-multidefect} breaks down the multi-defect
score of Eq.~$(\ref{eq:blueprintobjective})$, which is used to
evaluate the quality of multi-target designs. Recall that the total
score is composed of the term $\frac{1}{k} \sum_{\ell=1}^{k} (E(S,
R_\ell) - \EnsE(S))$, which evaluates the distances of the energies of
target structures to the minimum free energy (Distance to MFE), and
the term $\frac{1}{2\binom{k}{2}} \sum\limits_{1\leq\ell<j\leq
  k}|E(S,R_\ell) - E(S,R_j)|$, which evaluates the similarity of the
target structure energies of the target structures (Heterogeneity).

\label{appsec:multidefect}
\begin{figure}[h!]
\includegraphics[width=.48\textwidth]{Figs/statistics-Term1}
\includegraphics[width=.48\textwidth]{Figs/statistics-Term2}
\caption{Break-down of average MultiDefect values into their two components.}
\label{fig:contribtions-multidefect}
\end{figure}



\section{Approximate counting and random generation}
In fact, not only is $\#{\sf BIS}$ a reference problem in counting complexity, but it is also a landmark problem with respect to the complexity of approximate counting problems. In this context, it is the representative for a class of $\#{\sf BIS}$-hard problems~\citep{Bulatov2013} that are easier to approximate than $\# {\sf SAT}$, yet are widely believed not to admit any Fully Polynomial-time Randomized Approximation Scheme. Recent results reveal a surprising dichotomy in the behavior of $\#{\sf BIS}$: it admits a Fully Polynomial-Time Approximation Scheme (FPTAS) for graphs of max degree $\le 5$~\citep{Weitz2006}, but is as hard to approximate as the general $\#{\sf BIS}$ problem on graphs of degree $\ge 6$~\citep{Cai2016}. In other words, there is a clear threshold, in term of the max degree, separating (relatively) easy instances from really hard ones.

Additionally, let us note that, from the classic Vizing Theorem, any bipartite graph $G$ having maximum degree $\Delta$ can be decomposed in polynomial time in exactly $\Delta$ matchings. Any such matching can be reinterpreted as a secondary structure, possibly with crossing interactions (\Def{pseudoknots}). These results have two immediate consequences for the pseudoknotted version of the multiple design counting problem.
\begin{corollary}[as follows from~\citep{Weitz2006}]The number of designs compatible with $m\le 5$ pseudoknotted RNA structures can be approximated within any fixed ratio by a deterministic polynomial-time algorithm.
\end{corollary}
\begin{corollary}[as follows from~\citep{Cai2016}]
  As soon as the number of pseudoknotted RNA structures strictly exceeds $5$, \NumDesign is as hard to approximate as {\#{\sf BIS}}.
\end{corollary}

It is worth noting that the $\#{\sf P}$ hardness of \NumDesign does not immediately imply the hardness of generating a valid design uniformly at random, as demonstrated constructively by Jerrum, Valiant and Vazirani~\citep{Jerrum1986}. However, in the same work, the authors establish a strong connection between the complexity of approximate counting and the uniform random generation. Namely, they showed that, for problems associated with self-reducible relations, approximate counting is equally hard as (almost) uniform random generation. We conjecture that the (almost) uniform sampling of sequences from multiple structures with pseudoknots is in fact \#{\sf BIS}-hard as soon as the number of input structures strictly exceeds $5$, as indicated by~\citet{Goldberg2004}, motivating even further our parameterized approach.

\section{Tree decomposition for RNA design instances in practice}
\label{appsec:treedecomp}

For studying the typically expected treewidths and tree decomposition
run times in multi-target design instances, we consider five sets of
multi-target RNA design instances of different complexity. Our first
set consists of the Modena benchmark instances.

In addition, we generated four sets of instances of increasing
complexity. The instances of the sets RF3, RF4, RF5, and RF6, each
respectively specify 3,4,5, and 6 target structures for sequence
length 100.  For each instance (100 instances per set), we generated a
set of $k$ ($k=3,\dots,6$) compatible structures as follows
\begin{itemize}
\item Generate a random sequence of length 100;
\item Compute its minimum free energy structure (ViennaRNA package);
\item Add the new structure to the instances if the resulting base pair dependency graph is bipartite;
\item Repeat until $k$ structures are collected.
\end{itemize}
For each instance, we generated the dependency graphs in the base pair
model and in the stacking model. Then, we performed tree decomposition
(using strategy ``GreedyFillIn'' of LibTW~\citep{Dijk2006}) on each dependency
graph. The obtained treewidths are reported in
Fig.~\ref{fig:td-widths}, while Fig.~\ref{fig:td-times} shows the
corresponding run-times of the tree decomposition.

\revised{
  Finally, for further illustration, we show concrete tree decompositions for a selected instance in the benchmark set RF3 in Figure~\ref{fig:td-example}. Note that this figure is provided solely for illustrational purposes:
  First, it depicts the tree decomposition for a typical, realistic sampling task. Second, it exemplarily illustrates the typical impact of the energy model on the tree decomposition.
  Compared to the tree decomposition based on the stacking model, the tree decomposition for the base pair model is much simpler. This shows in many connected components, which correspond to independently solvable sub-problems, and fewer positions per bag (i.e. smaller tree width), which allows far more efficient evaluation per tree node. 
  Note that the complexity of the tree decomposition ultimately shows the complexity of the dependencies that need to be considered for simultaneous energy evaluation for all target structures. This complexity is substantially increased in the stacking model over the simpler base pair model.
}

\begin{figure}
  %\hspace*{2cm}\textbf{Base pair model}\hspace{4.75cm}\textbf{Stacking model}\\[-28pt]
  \centering\includegraphics[width=0.9\textwidth]{Figs/td-widths}
  \caption{Treewidths for multi-target RNA design instances of
    different complexity. Distributions of treewidths shown as boxplots for the base pair (left) and stacking model (right).}
  \label{fig:td-widths}
\end{figure}

\begin{figure}
  %\hspace*{2cm}\textbf{Base pair model}\hspace{4.75cm}\textbf{Stacking model}\\[-28pt]
  \centering
  \includegraphics[width=0.9\textwidth]{Figs/td-times}
  \caption{Computation time of tree decompositions for
    multi-target RNA design instances of different complexity.
    Distributions of times (in ms/instance) shown as boxplots for the base pair (left) and stacking model (right).}
  \label{fig:td-times}
\end{figure}


\begin{figure}[t!]
  %% the figure shows benchmark_inputs/RNAfold/3str/f3.100.0.inp
  \centering
  \verbatiminput{Figs/f3_100_0.txt}
  \includegraphicstop[width=0.6\textwidth]{Figs/td-example-basepair}%
  \includegraphicstop[width=0.35\textwidth]{Figs/td-example-stacking}
  \caption{Example instance from RF3 (top) with its tree decompositions in the base pair (left) and stacking model (right). The respective treewidths are 2 and 12.}
  \label{fig:td-example}
\end{figure}


\section{Tree decomposition with hyper-dependencies}
\label{appsec:dependency-cliques}

Our implementation relies on external tools for the tree decomposition, which do not directly support tree decomposition of hyper-graphs. Therefore it is not immediately obvious how 
to obtain a suitable tree decomposition, such that even multi-ary contributions are respected and a cluster tree can be generated.

Crucially, one can show that, as long as certain vertices of a graph $G$ from a clique, there exists at least one node in the tree decomposition of $G$ that contains all such vertices.
%
This allows us to generate suitable tree decompositions, which respect the hyper-edges of our dependency graph, by expanding the hyper-edges to cliques, and then calling the tree-decomposer on the resulting (non-hyper-)graph.

%
While the result is certainly part of folklore, we emphasize the importance for the generality of this work and present a brief direct proof for convenience.

\begin{lemma}\label{lem:cliques}
Let $G=(V,E)$ be an undirected graph, and  $(T,\chi)$ be a tree decomposition for $G$. For each clique $C\subseteq V$, there exists a node $u \in T$ such that $C\subseteq\chi(u)$.
\end{lemma}

%\begin{proof}
% \newcommand{\tn}{v_{\rm T}} %% node in tree
% \newcommand{\TransVars}[1]{{\rm tverts}(#1)}
% \newcommand{\Children}[1]{{\rm Children}(#1)}
%  For the sake of simplicity, let us consider $T$ as rooted on an arbitrary node, inducing an orientation, and denote by $\TransVars{\tn}\in V$ the set of vertices found in the node $\tn$ or its descendants, namely
%    $$\TransVars{\tn} = \chi(\tn) \cup \bigcup_{\tn'\in\Children{\tn}} \TransVars{\tn'}.$$
%
%  Now consider (one of) the deepest node(s) $\tn\in T$, such that $C\subseteq\TransVars{\tn}$. We are going to prove that $C\subseteq\chi(\tn)$, using contradiction, by showing that $C\not\subseteq\chi(\tn)$ implies that $T$ is not a tree decomposition.
%
%  Assume that $C\not\subseteq\chi(\tn)$, then there exists a node $v'\notin\chi(\tn)$ whose presence in $\TransVars{\tn}$ stems from its presence in some descendant of $\tn$. Let us denote by $\tn'\neq \tn$ the closest descendant of $\tn$ such that $v'\in\chi(\tn')$. Now, consider a node $v\in C$ such that $v\in \TransVars{\tn'}$ and $v\notin \TransVars{\tn'}$. Such a node always exists, otherwise $\tn'$, and not $\tn$, would be the deepest node such that $C\subseteq \TransVars{\tn'}$. From the definition of the tree decomposition, we know that neither $\tn'$ nor its descendants may contain $v$. On the other hand, none of the parents or siblings of $\tn'$ may contain $v'$. It follows that is no node $\tn''\in T$ whose vertex set $\chi(\tn'')$ includes, at the same time, $v$ and $v'$. Since both $v$ and $v'$ belong to a clique, one has $\{v,v'\}\in E$. The absence of a node in $T$ capturing an edge in $E$ contradicts our initial assumption that $T$ is tree decomposition for $G$.
%
%  We conclude that $\tn$ is such that $C\not\subseteq\chi(\tn)$.
%\end{proof}

\begin{proof}
  \newcommand{\TransVars}[1]{{\rm tverts}(#1)}%
  Root $T$ at an arbitrary tree node $r\in T$, which induces a parent/child relation between tree nodes.
  We say a tree node $u$ \emph{represents} the node $v\in V$ (respectively, the set of nodes $X\subseteq V$) iff $v\in\chi(u)$ ($X\subseteq\chi(u)$).
  Moreover, denote by $\TransVars{u}\subseteq V$ the vertices
  represented by the nodes of the subtree of $u$, i.e.
  $$\TransVars{u} := \chi(u) \cup \bigcup_{\text{children $u'$ of u}} \TransVars{u'}.$$

  Assume there is no node in T that represents $C$.

  Let $u$ denote the node in $T$ with maximal distance to the root $r$,
  such that still $C\subseteq\TransVars{u}$.
  Since there is no single node $u$ that represents $C$, this maximal node is unique, since
  if a node $u$, $C\subseteq\TransVars{u}$, has two subtrees that cover $C$, then $u$ must represent $C$ due to property 2 of Def.~\ref{def:treedecomp}. 

  Let $C'$ be $C-\chi(u)$.
  $C'$ cannot be empty, since otherwise $u$ represents $C$i.
  For exactly one of the children $u'$ of $u$,
  $C'\subseteq\TransVars{u'}$, since otherwise for
  some node $v'\in C'$, the subtree of the nodes representing $v'$ would be disconnected (property 2 of Def.~\ref{def:treedecomp}). Now, pick some $v'\in C'$ and some
  $v''\in C-C'$, which must be represented by $u$ or some child $u''$ of $u$. In both cases, there cannot
  be any node in T that represents the edge $\{v',v''\}\subseteq C$, since $v'$ can only be represented 
  by nodes in the subtree of $u'$. Contradiction.
\end{proof}


This result implies that classic tree decomposition algorithms and, more importantly, implementations can be directly re-used to produce decompositions that capture energy models of arbitrary complexity, functions of arbitrary arity. Indeed, it suffices to add a clique, involving the parameters of the function, and Lemma~\ref{lem:cliques} guarantees that the tree decomposition will feature one node to which the function can be associated.


    \section{Correctness of the FPT partition function algorithm}
    \label{appsec:correctness}

    \begin{theorem}[Correctness of Alg.~\ref{alg:pf}]
      \label{the:pfalgo-correctness}
      As computed by Alg.~\ref{alg:pf} for cluster tree $(T,\chi,\phi)$,
      the messages $\Message{u}{v}$, for all edges $u\to{}v\in T$, yield
      the partition functions of subtree of $u$ for the partial sequences
      $\val\in\partseqs(\separator{u}{v})$, i.e. the messages satisfy
      \begin{equation}
       \evalfor{\Message{u}{v}}{\val} = \sum_{\val'\in\partseqs(\chi(T_r(u))-\separator{u}{v})} \quad
       \prod_{f\in\phi(T_r(u))} \exp(-\evalfor{f}{\substitute{\val'}{\val}}),\label{eq:pfalgo-correct}
     \end{equation}
     where $\chi(T_r(u))$ denotes all $\chi$-assigned positions of nodes in $T_r(u)$;
     respectively $\phi(T_r(u))$; all $\phi$-assigned functions.
    %
    \end{theorem}

    \begin{proof}
      Note that in more concise notation, Alg.~\ref{alg:pf} computes
      messages such that
    \begin{equation}
      \evalfor{\Message{u}{v}}{\val} := \sum_{\val'\in\partseqs(\difference{u}{v})}\quad
      \prod_{f\in \phi(u) } \exp(-\evalfor{f}{\substitute{\val'}{\val}}) \prod_{(w\to{}u) \in T} \evalfor{\Message{w}{u}}{\substitute{\val'}{\val}}.\label{eq:messages}
    \end{equation}

    Proof by induction on $T$. If $u$ is a leaf, $\chi(r) = \chi(T_r(u))$,
    there are no messages sent to $u$, and $\phi(u) = \phi(T_r(u));$ implying
    Eq.~$(\ref{eq:pfalgo-correct}).$
    %
    Otherwise, since the algorithm traverses edges in postorder, $u$ received from its children
    $w_1,\dots,w_q$ the messages $\Message{w_1}{u}, \dots, \Message{w_q}{u}$, which satisfy Eq.~$(\ref{eq:pfalgo-correct})$ (induction hypothesis). Let $\val\in\partseqs(\separator{u}{v})$; then, $\evalfor{\Message{u}{v}}{\val}$ is computed by the algorithm according to Eq.~$(\ref{eq:messages})$. We rewrite as follows
    \begin{align*}
      & \sum_{\val'\in\partseqs(\difference{u}{v})}\quad
        \prod_{f\in \phi(u) } \exp(-\evalfor{f}{\substitute{\val'}{\val}})
        \prod_{(w\to{}u) \in T} \evalfor{\Message{w}{u}}{\substitute{\val'}{\val}}\\
      & = \sum_{\val'\in\partseqs(\chi(u)-\separator{u}{v})}\quad
        \prod_{f\in \phi(u) } \exp(-\evalfor{f}{\substitute{\val'}{\val}})
        \prod_{i=1}^q \evalfor{\Message{w_i}{u}}{\substitute{\val'}{\val}}\\
      & =_{IH}
        \sum_{\val'\in\partseqs(\chi(u)-\separator{u}{v})}\quad
        \prod_{f\in \phi(u) } \exp(-\evalfor{f}{\substitute{\val'}{\val}})
        \prod_{i=1}^q \sum_{\val''\in\partseqs(\chi(T_r(w_i))-\separator{w_i}{u})} \quad
        \prod_{f\in\phi(T_r(w_i))} \exp(-\evalfor{f}{\substitute{\val''}{\substitute{\val'}{\val}}}) \\
    & =_{*}
        \sum_{\val'\in\partseqs(\chi(u)-\separator{u}{v})}\quad
      \sum_{\val''\in\partseqs(\bigcup_{i=1}^q\chi(T_r(w_i))-\separator{w_i}{u})} \quad
      \prod_{f\in \phi(u) } \exp(-\evalfor{f}{\substitute{\val'}{\val}})
      \prod_{f\in\phi(T_r(w_i))} \exp(-\evalfor{f}{\substitute{\val''}{\val'} \cup \val}) \\
      & =_{(**)} \sum_{\val'\in\partseqs(\chi(T_r(u))-\separator{u}{v})}\quad
        \prod_{f\in \phi(T_r(u)) } \exp(-\evalfor{f}{\substitute{\val'}{\val}})\\
    \end{align*}
    To see (*) and (**), we observe:
    \begin{itemize}
    \item The sets $\chi(u)-\separator{u}{v}$ and
      $\chi(T_r(w_i))-\separator{w_i}{u}$ are all disjoint due to
      Def.~\ref{def:treedecomp}, property 2. First, this property implies
      that any shared position between the subtrees of $w_i$ and $w_j$
      must be in $\chi(w_i)$, $\chi(w_j)$ and $\chi(u)$, thus the
      positions of $\chi(T_r(w_i))-\separator{w_i}{u}$ are
      disjoint. Second, if a position $\chi(T_r(w_i))$ occurs in
      $\chi(u)$, it must occur in $\chi(w_i)$ and consequently in $\separator{u}{v}$.
    \item The union of the sets $\chi(u)-\separator{u}{v}$ and
      $\chi(T_r(w_i))-\separator{w_i}{u}$ is $\chi(T_r(u))-\separator{u}{v}).$
    \end{itemize}

    \end{proof}

    \section{General complexity of the partition function computation by cluster tree elimination and generation of samples}
    \label{appsec:algcomplexity}

    \begin{proposition}
      \label{prop:general-complexity}
    Given a cluster tree $(T,\chi,\phi)$, $T=(V,E)$ of the set of contributions $\F{}$ with treewidth $w$ and maximum separator size $s$, computing the partition function by Algorithm~\ref{alg:pf} takes $O((|F|+|V|)\cdot 4^{w+1})$ time and $O(|V| 4^s)$ space (for storing all messages). The sampling step has time complexity of $O((|F|+|V|)\cdot 4^D)$ per sample.
    \end{proposition}

    \begin{proof}[Proposition~\ref{prop:general-complexity}]
    Let $d_u$ denote the degree of node $u$ in $T$, $s_u$ is the size of the separator between
    $u$ and its parent in $T$ rooted at $r$. For each node in the cluster tree, Alg.~\ref{alg:pf} computes one message by combining $(|\phi(u)|+d_u-1)$ functions, each time enumerating $4^{|\chi(u)|}$ combinations; Alg.~\ref{alg:sampling} computes $4^{|\chi{u}|-s_u}$ partition functions each time combining $(|\phi(u)|+d_u-1)$ functions.  $4^{|\chi(u)|}$ is bound by $4^{w+1}$ and $4^{|\chi{u}|-s_u}$ by $4^D$; moreover $\sum_{u\in V} (|\phi(u)|+d_u-1) = |F|+|V|-1$.
    \end{proof}


    \section{Exploiting constraint consistency to reduce the complexity}\label{sec:improvedComplexity}

    While Alg.~\ref{alg:pf} computes messages values for
    \emph{all} possible combinations of nucleotides for the positions
    % in the separator set,
    % yp: for all the positions in a node, right?
    in a node,
    we observe here that many such combinations are \emph{not} required for computing all relevant
    partition functions. In particular, the algorithm can be restricted to
    consider only \Def{valid} combinations, satisfying the (hard)
    constraints induced by valid base pairs.

    The given structures in the RNA design problem impose constraints on
    the sequences for ensuring canonical (aka complementary)
    base pairing. These constraints can be exploited in a particularly
    simple and effective way to reduce the complexity.  As previously
    noted by \citet{Flamm2001}, the base pair complementarity induces a
    bi-partition of each connected component within the base pair
    dependency graph, such that the nucleotides assigned to the two set of
    nodes in the partition are restricted to values in $\{\Ab,\Gb\}$ and
    $\{\Cb,\Ub\}$ respectively. We call a partial sequence \Def{cc-valid},
    iff its determined positions are consistent with such a separation for
    all determined positions of the same connected component.

    % Let $CC=\{cc_1$, $cc_2, \dots\}$ denote the vertex sets of the
    % connected components of the base pair dependency graph. In this graph,
    % let each component have the bi-partition $cc_i=cc^0_i\cup cc^1_i$.

    One can now modify Alg.~\ref{alg:pf}, on a tree decomposition
    $(T,\chi)$, such that the values of messages
    $\Message{u}{v}$ are computed only for cc-valid
    partial sequences $\val\in\partseqs(\separator{u}{v})$. Moreover, the
    loop over $\val'\in\partseqs(\difference{u}{v})$ is restricted, such
    that $\substitute{\val}{\val'}$ are cc-valid. Analogous restrictions are
    then implemented in the sampling algorithm Alg.~\ref{alg:sampling}.

    The correctness of the modified algorithm follows from the same
    induction argument, where the message computation over one node
    evaluates messages from its children only at cc-valid partial
    sequences. The result of this computation is a message, which corresponds
    to the partition function, restricted to cc-valid partial sequences.
    Since invalid sequences have infinite energy, they do not contribute to
    the partition function, and the partition function restricted to cc-valid sequences coincides
    with the initial one.



    This restriction drastically improves the time
    complexity. Indeed, for any given node $v$, the original algorithm sends message for
     $\chi(v):=\substitute{\val}{\val'}$ such that
    $\val\in\partseqs(\separator{u}{v})$ and
    $\val'\in\partseqs(\difference{u}{v})$, while the modified algorithm
    only considers cc-valid assignments for $\chi(v)$. Remark that, in any connected component $cc$,
    assigning some nucleotide to a position reduces cc-valid assignments to (at most)
    two alternatives for each of the $|cc|-1$ remaining positions. It follows that, for a node $v$ featuring positions from $\#cc(v)$ distinct connected components $\{cc_1,cc_2\ldots\}$ in the base pair dependency graph, the number of cc-valid assignments to positions in $\chi(v)$ is exactly
    $$4^{\#cc(v)}\prod_{i=1}^{\#cc(v)} 2^{|cc_i|-1} = 2^{\#cc(v)}\, 2^{|\chi(v)|} \in \Theta(2^{\#cc}\, 2^{w+1}),$$
    for a single node, where $\#cc$ is the total number of connected components in the base pair dependency graph, and $w$ is the tree-width of the tree decomposition $T$. Since the number of nodes in $T$ is in $\Theta(n)$, and the number of atomic energy contributions associated with $k$ structures is in $\mathcal{O}(k\,n)$, then the overall complexity grows like $\Theta(n\, k\, 2^{\#cc}\, 2^{w+1})$.

    %For each connected component having at least a position $i$ in $\chi(v)$,
    %the algorithm considers assigning any possible nucleotide $x\in \Sigma$ to $i$ and restricts
    % the assignment of  for
    %any remaining position $j$ of the same connected component, it restricts the domain of $j$ to base-pairs that are consistent with the parity .
    %
    %
    %Let $c(v)$ be the number of connected components involving positions
    %in $\chi(v)$; then, the first stage enumerates $2^{c(v)}$
    %combinations. For each such combination, the second stage enumerates
    %only $2^{|\chi(v)|}$ partial sequences, since there remain only two
    %possible nucleotide choices for each position. All message values for
    %node $v$ are thus computed in time
    %$\Theta(2^{c(v)+|\chi(v)|})$. Consequently, the total time complexity
    %of the modified algorithm is $$O(nk2^{\hat w}),$$ where $n$ is the RNA
    %length, $k$ is the number of structures, and
    %$\hat w := \max_{v\in T} c(v)+|\chi(v)|$.
    %%
    %From this directly follows the slightly looser complexity
    %bound $$O(nk2^{w+1}2^{c})$$ in terms of treewidth $w$ and the maximum
    %number $c$ of connected components represented in a node of the tree
    %decomposition.  Notably, $\hat w$, as well as $w+1+c$, can not exceed
    %$2(w+1)$, since $c\leq w+1$. Consequently the modified algorithm does
    %never increase the original complexity.

    Finally, we remark that even stronger time savings could be possible
    in practice, since cc-valid partial sequences can still violate
    complementarity constraints, e.g. by assigning C and A to positions in
    different sets of a partition, thus satisfying the bi-partition
    constraints, where the positions base pair directly, rendering the
    partial sequence invalid. Moreover, applications of the sampling
    framework can introduce additional constraints that further reduce
    the number of valid partial subsequences. However, exploiting all such
    constraints, in a complete and general way, would likely cause significant
    implementation overhead, while not significantly improving
    the asymptotic complexity.


    %\section{Exploiting the bipartite nature of base pair dependency
    %  graphs to reduce the complexity}\label{sec:first-improvedComplexity}
    %\textcolor{red}{\textbf{TODO: discuss and merge with/replace by previous Section}}
    %
    %As already noted by \citet{Flamm2001}, the requirement of canonical
    %base pairing induces a bi-partition of each connected component within
    %the base pair dependency graph, such that the nucleotides assigned to
    %the two set of nodes in the partition are restricted to values
    %$\{\Ab,\Gb\}$ and $\{\Cb,\Ub\}$ respectively.
    %%
    %It follows that, within each connected component of the base pair
    %dependency graph, the assignment of any position drastically restricts
    %the domain of the remaining positions, \emph{i.e.} they may now be
    %assigned to only 2 out of the original 4 nucleotides.
    %\newcommand{\Parity}[1]{p_{#1}} To exploit this property, and further
    %reduce the exponential factor of the complexity, we introduce the
    %notion of \Def{parity} of a vertex/position, whereby vertices of
    %\Def{even} (resp. \Def{odd}) polarities may only be assigned values in
    %$\{\Ab,\Gb\}$ (resp. $\{\Cb,\Ub\}$). Neighbors of an odd vertex must
    %be even and vice versa, so the choice of a parity for any single
    %vertex caracterizes the parity of all vertices in a bipartite
    %connected subgraph.
    %
    %Let $CC=\{cc_1,cc_2,\ldots\}$ denote the connected components of the base pair dependency graph, we consider a modified version of the cluster tree, obtained by:
    %\begin{enumerate}
    %\item Electing, in each connected component $cc_i$, the first position $v_i^\star$ from the component encountered from the root in a pre-order traversal of the cluster tree;\label{step:election}
    %\item Introducing new variables $\mathcal{P}=\{\Parity{1},\ldots,\Parity{|CC|}\}$, representing the parity of elected vertices;
    %\item Adding, to each node $x$ in the tree decomposition, the parity variables of connected components that are represented in the node, \emph{i.e.} such that at least one of the positions in the connected component is in $\chi(x)$; \label{step:addparities}
    %\item Introducing, in the tree decomposition, a chain of intermediate nodes to fix cases where more than a single (parity) variable is introduced between a parent and its child.\label{step:intermediates}
    %\end{enumerate}
    %Note that, since connected components correspond to connected subtrees in the tree decomposition, then adding those variables preserves the properties of a tree decomposition. Also, each node in the former cluster tree introduces at most one new variable compared to its parent, so the elected node is uniquely defined by the rule stated in Step~\ref{step:election}. Finally, we note that the parity of a variable $v\in cc_i$ is entirely characterized by the parity $\Parity{i}$ of $v_i^\star$, and the parity of the distance between $v$ and $v_i^\star$ in the base pair dependency graph. Namely, the parity of $v$ is $\Parity{i}$ if the distance between $v$ and $v^{\star}_i$ is even, and opposite to $\Parity{i}$ if odd. It follows that, thanks to the new variables introduced in Step~\ref{step:addparities}, the domain of each of the original variables can be reduced to two alternatives instead of the original four.
    %
    %The computation of Alg.~\ref{alg:pf} on the new cluster tree, considering reduced assignments for position variables and additional odd/even assignments for parity variables, has complexity in $\mathcal{O}(n\,k\,2^{w+1}\,2^{c})$, where $n$ is the RNA length, $k$ is the number of structures, $w$ is the tree-width of the unmodified cluster tree, and $c$ is the maximum number of connected components represented in a node. It should be noted that $c\le \min(|CC|,w+1)$, so that the new complexity cannot be larger than the one stated in Th.~\ref{th:complexities}. Also, note that the number of nodes introduced by Step~\ref{step:intermediates} is bounded by $|CC|$, so that the introduction of these intermediate nodes does not impact the worst-case complexity. For the same reason, the complexity of the stochastic backtrack remains unchanged.


\section{Monotonicity of the partial derivatives within weight calibration}
\label{sec:weight_derivatives}
%
In weighted distributions, one witnesses a fairly predictable impact of the variation of any weight $\pi_\ell$ over the expected value $\mathbb{E}(E_\ell\mid \pmb{\pi})$, $\pmb{\pi}:= (\pi_1\cdots\pi_k)$, of the free energy $E_\ell$ of structure $\ell$.  Let us  first remind the probability of a sequence $S$ in the weighted distribution
\begin{align*}
  \mathcal{B}_{\pmb{\pi}}(S) &= \prod_{i=1}^{k} \pi_i^{-E_i(S)}, &
  \partfun{\pmb{\pi}}&=\sum_{S'}\mathcal{B}_{\pmb{\pi}}(S') &
    \text{and}& &
  \mathbb{P}(S\mid \pmb{\pi}) &= \frac{\mathcal{B}_{\pmb{\pi}}(S)}{\partfun{\pmb{\pi}}}.
  \end{align*}

Remind also the definition of the expectation of $E_\ell(S)$, for $S$ a Boltzmann-distributed sequence:
$$\mathbb{E}(E_\ell\mid \pmb{\pi}) = \sum_S E_\ell(S)\cdot \mathbb{P}(S\mid \pmb{\pi}).$$

We first remark that the partial derivative of $\mathcal{B}$ yields
\begin{align*}
  \frac{\partial \mathcal{B}_{\pmb{\pi}}(S)}{\partial \pi_\ell} = -E_\ell(S)\cdot \pi_\ell^{-E_\ell(S)-1}\prod_{\substack{i=1\\i\neq \ell}}^{k} \pi_i^{-E_i(S)} = \frac{-E_\ell(S)}{\pi_\ell}\cdot\mathcal{B}_{\pmb{\pi}}(S) = -E_\ell(S)\cdot \mathbb{P}(S\mid \pmb{\pi})\cdot \frac{\partfun{\pmb{\pi}}}{\pi_\ell }
\end{align*}
while the partial derivative of $\mathcal{Z}$ gives
\begin{align*}
  \frac{\partial \partfun{\pmb{\pi}}(S)}{\partial \pi_\ell} = \sum_{S'} -E_\ell(S')\cdot \mathbb{P}(S'\mid \pmb{\pi})\cdot \frac{\partfun{\pmb{\pi}}}{\pi_\ell }= -\mathbb{E}(E_\ell\mid \pmb{\pi})\cdot \frac{\partfun{\pmb{\pi}}}{\pi_\ell}.
\end{align*}
From these expressions, we conclude that
\begin{align*}
  \frac{\partial \mathbb{E}(E_\ell\mid \pmb{\pi})}{\partial \pi_\ell} &= \sum_S E_\ell(S)\cdot\frac{\partial \mathbb{P}(S\mid \pmb{\pi})}{\partial \pi_\ell}\\
  %
  & = \sum_S E_\ell(S)\left(\frac{\frac{\partial \mathcal{B}_{\pmb{\pi}}(S)}{\partial \pi_\ell}}{\mathcal{Z}_{\pmb{\pi}}} - \frac{\frac{\partial \mathcal{Z}_{\pmb{\pi}}}{\partial \pi_\ell}\cdot\mathcal{B}_{\pmb{\pi}}(S)}{\mathcal{Z}_{\pmb{\pi}}^2}\right)\\
  %
  & = \sum_S E_\ell(S)\left(\frac{-E_\ell(S)\cdot \mathbb{P}(S\mid \pmb{\pi})\cdot \frac{\mathcal{Z}_{\pmb{\pi}}}{\pi_\ell }}{\mathcal{Z}_{\pmb{\pi}}} + \frac{\mathbb{E}(E_\ell\mid \pmb{\pi})\cdot \frac{\mathcal{Z}_{\pmb{\pi}}}{\pi_\ell}\cdot\mathcal{B}_{\pmb{\pi}}(S)}{\mathcal{Z}_{\pmb{\pi}}^2}\right)\\
  %
  & = \sum_S - \frac{E_\ell(S)^2\cdot\mathbb{P}(S\mid \pmb{\pi})}{\pi_\ell} + \frac{\mathbb{E}(E_\ell\mid \pmb{\pi})}{\pi_\ell}\sum_S E_\ell(S)\cdot \mathbb{P}(S\mid \pmb{\pi})\\
  & = -\frac{\mathbb{E}(E_\ell^2\mid \pmb{\pi}) - \mathbb{E}(E_\ell\mid \pmb{\pi})^2}{\pi_\ell}
\end{align*}
In the numerator of the above expression, one recognizes the variance of the distribution of $E_\ell$.
Remark that a variance is always non-negative and, in our case, also strictly positive for $\pmb{\pi}$, $\pi_\ell>0$, as soon as there exist at least two distinct sequences $S$ and $S'$ such that $E_\ell(S)\neq E_\ell(S')$.
Moreover, weights are always positive so the partial derivative in $\pi_\ell$ is always positive. Ultimately, it is always possible to increase (resp. decrease) the expected free energy of a structure by simply decreasing (resp. increasing) its weight, supporting our weight optimization procedure.



\section{Detailed results of MultiDefect analysis}\label{sec:validity}
N/A values correspond to data that could not be obtained by the time of this submission for two main reasons: In the case of the initial sampling (left columns), they correspond to instances which, in conjunction with an expressive energy model, resulted in very high tree-width, leading to unreasonable memory requirements incompatible with our available computing resources; The case of missing values after optimization  (right columns), they indicate situations where the initial optimization took too long ($\approx$ 1 day) and was killed.
\input{table}


\bibliographystyle{vancouver}
%\bibliographystyle{achemnat}
%\bibliographystyle{plainnat}
%\bibliographystyle{abbrv}
%\bibliographystyle{bioinformatics}
%
%\bibliographystyle{plain}
%
\bibliography{biblio}


\end{document}
